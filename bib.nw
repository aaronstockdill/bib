% -*- mode: latex; mmm-noweb-code-mode: sml-mode; -*-
\documentclass[10pt, a5paper, twoside]{mybook}
\usepackage{noweb}

\title{The \texttt{bib} Reference Manager}
\author{Aaron Stockdill}
\date{Version 0.1.0}

\begin{document}

\pagestyle{empty}
\maketitle

\frontmatter

\tableofcontents

\mainmatter
\pagestyle{headings}

\part{User guide}

\part{Library}

\noindent
\textbf{A short note on style}
\vspace*{2ex}

\noindent
The code for [[bib]] is written in Standard ML.\@
While coding style guides are few and far between,
common-sense rules such as spacing and indentation are enforced.
The most prominent feature is the use of currying-by-default:
only with good reason are functions defined with tuples as parameters.

Variable names use [[camelCase]],
signatures use [[UPPERCASE]],
structures will use [[PascalCase]],
types [[underscore_naming]],
and constructors will use [[UPPERCASE_WITH_UNDERSCORES]].
This is strictly enforced to avoid confusion.

\chapter{The objectives of \texttt{bib}}

Writing code is always an attempt to answer the question
`how can I do this better?'
In this case,
the desire for the [[bib]] library
is born out of a desire for a reference manager that fits the way I work.
There are many tools that are close:
BibDesk is almost perfect,
apart from the fact that libraries and \BibTeX{} files
are the same thing;
Mendeley fixes that particular quirk but then makes demands about how it stores PDF files
(and that is before getting into its ownership).
I could go on,
but it would seem apparent that I am a fussy filer---%
the only option left, obviously,
was to write a bibliography manager myself.

A good bibliography manager,
like a good camera,
is the one that gets used,
so we approach the architecture of [[bib]]
as a discrete front-end--back-end design.
By producing the [[bib]] back-end as a library
for other systems to call,
we decouple the problem of logic from interface.
This means we can have implementations for a wide variety of platforms and modalities.
Standard software engineering practice,
but useful to note when reading this manual.

As for the features of the [[bib]] library,
they are five-fold.
\begin{itemize}
\item To create and maintain libraries of references.
\item To automatically update `projects' of references as \BibTeX{} files as they are edited.
\item To support rapid searching, filtering, and sorting of references based on types, fields, and fuzzy matching.
\item To allow automatic filing of resources attached to references, ideally on a per-library basis.
\item To seamlessly import existing \BibTeX{} files for inclusion into a library.
\end{itemize}
Each of these will be explored in more detail in subsequent chapters,
along with details of the file format and support functions.
This project will also provide opportunities for
interesting string algorithms,
data structures,
and general code hackery.


\chapter{The library}

Any reference management software needs libraries.
There are two pieces that can be considered the library:
the file format storing the data,
and the in-memory data structure.
Each must be transformable to the other,
so they are not unrelated.
To this end, we will explore the two together,
starting at the level of the \emph{reference}.

\section{Bibliographic references}

A bibliographic reference is a general grouping,
consisting of a [[citeKey]],
a [[recordType]],
and some fields mapping to [[bibValue]]s (fields are strings, for simplicity).
The fields are theoretically some finite set
(for example title, author, publisher)
but they vary dramatically by [[recordType]]
Hence references consist of just two fixed attributes
and this collection of fields and values.
We can summarise this with the data type [[reference]].
<<concrete type for reference>>=
datatype reference = REFERENCE of {
  citeKey: cite_key,
  recordType: record_type,
  fields: bib_value StringDict.dict
}
@

We will explore the [[cite_key]], [[record_type]], [[bib_value]], and [[StringDict.dict]] types
in more detail later.
For now, we can take the first three as string-like, and the last as a dictionary
(obviously enough).

@
Our [[reference]] datatype needs to be stored in a file,
so we must encode and decode it to some serialized form.
A simple encoding to XML might be as follows:
\begin{verbatim}
<reference>
  <cite-key>bobson99</cite-key>
  <record-type>article</record-type>
  <fields>
    <field>
      <key>title</key>
      <value>On foo-ing the bars - a summary</value>
    </field>
    <field>
      <key>author</key>
      <value>
        <author>
          <fname>John</fname>
          <lname>Bobson</lname>
        </author>
      </value>
    <field>
  </fields>
</reference>
\end{verbatim}
Verbose, but very readable.
There are several pieces not directly relevant to the reference
(such as the \texttt{author} stuff),
but the broad strokes can be seen clearly.
Ensuring backwards-compatibility should be simple with this format,
and extending it for new properties is straight-forward.

Because encoding the reference is simpler than reading it,
we will start there.
The function [[xmlEncodeReference]]
will perform the encoding in the obvious way.
<<encode reference to XML>>=
(* xmlEncodeReference: reference -> string *)
fun xmlEncodeReference refr =
    let
        val { citeKey=k,
              recordType=r,
              fields=f
            } = refr;
        val citeXml = xmlEncodeCiteKey k;
        val recordXml = xmlEncodeRecordType r;
        val fieldsXml = xmleEncodeFields f
    in
        "<reference>" ^
            citeXml ^
            recordXml ^
            fieldsXml ^
        "</reference>"
    end;
@

@
For example, we would expect the following correspondence:
<<XML encoding tests>>=
test("Validate simple reference encoding.",
     assert_equals_string("<reference>" ^
                          "<cite-key>testkey</cite-key>" ^
                          "<record-type>article</record-type>" ^
                          "<fields></fields>" ^
                          "</reference>",
          xml_encode_reference (REFERENCE {
                                     citeKey = CITE_KEY "testkey",
                                     recordType = ARTICLE,
                                     fields = StringDict.empty
                               })));
@

@
Decoding a reference string is significantly more complicated:
we are parsing XML, which is no mean task.
In chapter~\ref{chap:parser},
we discuss the implementation of parser combinators;
these form the basis of our XML parser,
we simply need to compose them together.

@
First we aim to produce a valid [[reference]] record
with [[xmlDecodeReference]].
We skip any whitespace,
and then read in the opening [[<reference>]] tag
before again skipping any whitespace.
We now rely on other parsers to handle the parsing of
the cite key, the record type, and the fields of this reference.
Finally, we skip whitespace and read in the closing tag.
The overall structure is to read the opening tag,
the content,
and the closing tag.
All of our XML parsers will follow a similar structure,
because we are actually parsing a reduced subset of XML:\
we do not consider attributes.
<<decode XML to reference>>=
val xmlDecodeReference: record Parser.parser =
    Parser.whitespace >>
    Parser.consumeString "<reference>" >>
    Parser.whitespace >>
    xmlDecodeCiteKey    >>= (fn citeKey =>
    xmlDecodeRecordType >>= (fn recordType =>
    xmlDecodeFields     >>= (fn fields =>
    Parser.whitespace >>
    Parser.consumeString "</reference>" >>
    Parser.whitespace >>
    Parser.return (REFERENCE {
         citeKey = citeKey,
         recordType = recordType,
         fields = fields
   }))));
@

@
The syntax is a bit strange,
borrowing Haskell's monad notation
(although we lack the tidy `do' notation).
Read [[>>]] as `and then',
and [[>>=]] as `and then with'.
Everything else should be relatively obvious.

@
Seeing the parser in action might clarify things,
so for example we can attempt to parse a [[string]] to a [[reference]].
<<XML decoding tests>>=
test("Validate the decoding of a string to a reference",
     assert_equals_reference(
         REFERENCE {
             citeKey = CITE_KEY "testkey",
             recordType = ARTICLE,
             fields = StringDict.empty
         },
         xmlDecodeReference (
             "<reference>" ^
             "<cite-key>testkey</cite-key>" ^
             "<record-type>article</record-type>" ^
             "<fields></fields>" ^
             "</reference>"
         )
    ));
@

@
Citation keys are a fundamental part of referencing software:
these unique identifiers allow us to index references efficiently
and reference them from tools like \LaTeX{}.
In the interest of allowing for future expansion,
and some type safety,
we define a type for cite keys.
<<cite key type definition>>=
type cite_key = CITE_KEY of string;
@

@
Because we must be able to read and write them from the library,
we define some very basic XML encoders and parsers.
Starting with the encoder as before,
because it is simpler:
<<encode cite key to XML>>=
fun xmlEncodeCiteKey (CITE_KEY key) =
    "<cite-key>" ^ key ^ "</cite-key>";
@

And the obligatory example:
<<XML encoding tests>>=
test("Validate simple cite-key encoding",
     assert_equals_string(
         "<cite-key>testkey</cite-key>",
         xmlEncodeCiteKey (CITE_KEY "testkey")
    ));
@

Parsing the cite key is relatively trivial,
as it is just a string.
A cite key should be one or more
printable ASCII characters not in the set of [["@',#} {~\%]] %"
(which includes space).
<<read a cite key>>=
fun isValidCiteKeyChar c =
    let
        val badChars = [ #" ", #"\"", #"@", #"'", #",", #"\\",
                         #"#", #"{", #"}", #"~", #"%" ]
    in
        (Char.isAscii c)
        andalso not (Char.isControl c)
        andalso not (List.exists (fn x => x = c) badChars)
    end;

val readCiteKeyString: string Parser.parser =
    repeat (match isValidCiteKeyChar) >>= (fn cs => String.implode cs);

@
@ The full cite key parser falls out easily from helper parser.
We check for the correct tags and round up surrounding white space.
<<parse XML to cite key>>=
val xmlDecodeCiteKey: cite_key Parser.parser =
    Parser.whitespace >>
    Parser.consumeString "<cite-key>" >>
    readCiteKeyString >>= (fn citeKey =>
    Parser.whitespace >>
    Parser.consumeString "</cite-key>" >>
    Parser.whitespace >>
    Parser.return (CITE_KEY citeKey)));
@

@
As before,
we test our short function with an example.
<<XML decoding tests>>=
test("Decoding XML to cite key",
     assert_equals_cite_key(
         CITE_KEY "testkey",
         xmlDecodeCiteKey "<cite-key>testkey</cite-key>"
    ));
@

@
Sadly the record type is not so straight forward as the cite key.
Because it comes from a short set of possible values,
we can model it with a sum type;
the type safety associated with this is appreciated,
but not so simple to implement.
<<define the record-type datatype>>=
datatype record_type =
         ARTICLE
       | BOOK
       | BOOKLET
       | INBOOK
       | INCOLLECTION
       | INPROCEEDINGS
       | MANUAL
       | MASTERSTHESIS
       | MISC
       | PHDTHESIS
       | PROCEEDINGS
       | TECHREPORT
       | UNPUBLISHED;
@

@
While the type is long-winded, it is at least simple.
It is a similar case for the XML encoder:
<<encode record type to XML>>=
fun xmlEncodeRecordType recordType =
    "<record-type>" ^
    (case recordType of
         ARTICLE       => "article"
       | BOOK          => "book"
       | BOOKLET       => "booklet"
       | INBOOK        => "inbook"
       | INCOLLECTION  => "incollection"
       | INPROCEEDINGS => "inproceedings"
       | MANUAL        => "manual"
       | MASTERSTHESIS => "mastersthesis"
       | MISC          => "misc"
       | PHDTHESIS     => "phdthesis"
       | PROCEEDINGS   => "proceedings"
       | TECHREPORT    => "techreport"
       | UNPUBLISHED   => "unpublished"
    ) ^
    "</record-type>";
@

@
For example,
if we have a [[BOOK]],
the encoding would be as follows:
<<XML encoding tests>>=
test("Verify encoding record types",
     assert_equals_string(
         "<record-type>book</record-type>",
         xmlEncodeRecord BOOK
    ));
@

@
Decoding the XML is simply a case of
attempting the disjunction of all named record types.
<<read record type string into [[record_type]]>>=
val readRecordTypeString: record_type Parser.parser =
    let struct P = Parser in
    (P.attempt (P.consumeString "article" >> P.return ARTICLE)) <|>
    (P.attempt (P.consumeString "book" >> P.return BOOK)) <|>
    (P.attempt (P.consumeString "booklet" >> P.return BOOKLET)) <|>
    (P.attempt (P.consumeString "inbook" >> P.return INBOOK)) <|>
    (P.attempt (P.consumeString "incollection" >> P.return INCOLLECTION)) <|>
    (P.attempt (P.consumeString "inproceedings" >> P.return INPROCEEDINGS)) <|>
    (P.attempt (P.consumeString "manual" >> P.return MANUAL)) <|>
    (P.attempt (P.consumeString "mastersthesis" >> P.return MASTERSTHESIS)) <|>
    (P.attempt (P.consumeString "misc" >> P.return MISC)) <|>
    (P.attempt (P.consumeString "phdthesis" >> P.return PHDTHESIS)) <|>
    (P.attempt (P.consumeString "proceedings" >> P.return PROCEEDINGS)) <|>
    (P.attempt (P.consumeString "techreport" >> P.return TECHREPORT)) <|>
    (P.attempt (P.consumeString "unpublished" >> P.return UNPUBLISHED)) end;
@

@
We now just wrap it up in
<<decode XML to record type>>=
val xmlDecodeRecordType: record_type Parser.parser =
    Parser.whitespace >>
    Parser.consumeString "<record-type>" >>
    Parser.whitespace >>
    readRecordTypeString  (fn recordType =>
    Parser.whitespace >>
    Parser.consumeString "<record-type>" >>
    Parser.whitespace >>
    Parser.return recordType);
@

@
Earlier, in the [[reference]] datatype,
we made use of a [[StringDict.dict]] type;
this is a dictionary keyed over by strings.
The implementation is not overly complicated
(any introductory ML course should introduce how dictionaries are constructed),
so this subsection is lightly annotated.

\section{\BibTeX{} strings and names}

\section{The library collection}

\chapter{Projects}

\chapter{Searching, sorting, and filtering}

\chapter{External resources}

\chapter{Parser combinators}
\label{chap:parsers}

To conveniently parse the files required by this library,
we define some parser combinators.
The design of this structure is based on the Haskell `Parsec' library%
\footnote{\url{https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/parsec-paper-letter.pdf}}.
The combinators are usually quite simple,
and there are not many;
at a basic level there is just
[[return]],
[[match]],
[[<|>]] (read `or'),
and [[>>=]] (`and then with').
From these,
we build up all the pieces we will need.
<<signature of a parser>>=
signature PARSER =
sig
    <<definition of parser type>>

    val return: 'a -> 'a parser
    val match: (char -> bool) -> char parser
    val >>= : ('a parser * ('a -> 'b parser)) -> 'b parser
    val >> : ('a parser * 'b parser) -> 'b parser
    val <|> : ('a parser * 'a parser) -> 'a parser
    val attempt: 'a parser -> 'a parser
    val repeat: 'a parser -> 'a list parser

    val runParser: 'a parser -> string -> 'a consumed

    (* Some useful default parsers *)
    val whitespace: unit parser
    val consumeString: string -> unit parser
end
@

We begin with a definition of a [[parser]].
A [[parser]] is simply a function from a [[string]] to some output (and the rest of the unprocessed string),
for example it might produce the [[reference]] type.
<<definition of parser type>>=
datatype 'a reply = OK of ('a * string) | ERROR of string;
datatype 'a consumed = CONSUMED of ('a reply) | EMPTY of ('a reply);
type 'a parser = string -> 'a consumed;
@

@
The parser combinator [[return]] is the most basic,
essentially the `default' entry-point for building a parser.
It will always succeed on any input.
<<return combinator>>=
fun return x = fn input => EMPTY (OK (x, input));
@

@
A slightly more complex,
but much more useful,
combinator is the [[match]] combinator,
taking a character predicate and either consuming a matching character,
or failing.
<<match combinator>>=
fun match test =
    let
        fun stringHead s = SOME (String.sub (s, 0))
                           handle Subscript => NONE;
        fun stringTail s = String.extract(s, 1, NONE)
                           handle Subscript => s;
    in
    fn input =>
       case stringHead input of
           SOME c => (if test c
                      then CONSUMED (OK (case stringHead input of
                                             SOME c => (c, stringTail input)
                                           | NONE => raise Empty))
                      else EMPTY (ERROR input))
         | NONE   => EMPTY (ERROR input)
    end;
@

@
Because the grammar might require choice,
we define a combinator [[<|>]] (read `or')
where the most appropriate parser is used in a given scenario.
It proceeds by trying the first parser;
if this encounters an error we immediately attempt the second parser.
If the first parser does not error,
but does not consume any input,
then we see what the second parser does.
If the second parser also consumes nothing,
we default to the result of the first parser;
if the second parser does consume something, we favour this.
Finally, if the first parser consumes input,
we immediately favour it.
<<choice combinator>>=
infix 2 <|>
fun p <|> q =
    fn input =>
       case p input of
           EMPTY (ERROR input')   => q input
         | EMPTY (OK (a, input')) => (case q input' of
                                          EMPTY _  => EMPTY (OK (a, input'))
                                        | consumed => consumed)
         | consumed               => consumed;
@

@
The most complicated combinator is sequencing, [[>>=]].
This combinator will try and apply the first combinator,
leading to one of two cases:
should there be output, it passes it to the function [[f]] to run the next parser;
if there is no output, the error is carried through.
<<sequencing combinator>>=
infix 2 >>=
fun p >>= f =
    fn input =>
       case p input of
           EMPTY (ERROR input')      => (EMPTY (ERROR input'))
         | EMPTY (OK (x, input'))    => (f x) input'
         | CONSUMED (OK (x, input')) => CONSUMED (case (f x) input' of
                                                      CONSUMED reply2 => reply2
                                                    | EMPTY reply2 => reply2)
         | CONSUMED (ERROR input')   => (CONSUMED (ERROR input'))
@

@
There is a second sequencing combinator, [[>>]],
which ignores the result of the first parser and just immediately applies the second parser.
It can be defined concisely in terms of the [[>>=]] combinator.
<<sequencing combinator>>=
infix 2 >>
fun p >> q = p >>= (fn _ => q);
@

@
The next combinator we look at is very important.
Until now, the combinators we have defined are only valid for LL(1) grammars:
that is, grammars where you can make a decision with just one-step lookahead.
Many languages (such as XML) are \emph{not} LL(1),
but the more general LL($k$).
To extend our parser combinators to LL($k$),
we define the [[attempt]] combinator.
Essentially, it `fakes' the result such that if the parser reads input but hits an error,
the parser reports that it did not read any input.
<<attempt combinator>>=
fun attempt p =
    fn input =>
       case p input of
           CONSUMED (ERROR input') => EMPTY (ERROR input)
         | otherwise               => otherwise;
@

@
Finally we look at a combinator called [[repeat]].
This combinator essentially applies the parser as many times as possible.
The definition is (unsurprisingly) recursive.
<<repeat combinator>>=
fun repeat (p: 'a parser): ('a list parser) =
    p >>= (fn x =>
              (((repeat p) <|>
                (return [])) >>= (fn xs =>
                                     return (x::xs))));
@

@
Now that we have these `base' combinators,
we can build some simple parsers on top of them.
For example,
if we want a parser that will skip whitespace,
we might use the following:
<<whitespace parser>>=
val whitespace =
    let
        val _ = repeat (match Char.isSpace)
    in
        return ()
    end;
@

@
Another useful parser is one to consume a specific string,
which we call [[consumeString]].
The definition should almost be obvious.
<<specific string parser>>=
fun consumeString str =
    let
        fun consChrs ([]: char list): unit parser = return ()
          | consChrs (c::cs) = match (fn x => x = c) >> (consChrs cs)
    in
        consChrs (String.explode str)
    end;
@

@
Finally, the moment has come.
We are able to run the parser.
<<run parser>>=
fun runParser p input = p input;
@

@
We can arrange all of these parser pieces
into a [[Parser]] structure.
<<parser structure>>=
structure Parser :> PARSER =
struct
    <<definition of parser type>>
    <<return combinator>>
    <<match combinator>>
    <<sequencing combinator>>
    <<choice combinator>>
    <<attempt combinator>>
    <<repeat combinator>>
    <<run parser>>

    (* Some useful parsers *)
    <<whitespace parser>>
    <<specific string parser>>
end;
@



\part{Interfaces}

@
A small placeholder functions as the interface for now.
<<bib.sml>>=
<<signature of a parser>>
<<parser structure>>

fun main () =
    print "Hello, world!\n"

val _ = main()
@

\backmatter

\end{document}